{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56462880-0abe-492d-86ac-8ebc6dc7863b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sampling from the XY Model with Spline Flows: Direct Sampling of Spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95fe6e-7ff0-41a6-923f-436617c2a535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import actions\n",
    "import transforms\n",
    "import utils\n",
    "\n",
    "Tensor: TypeAlias = torch.Tensor\n",
    "BoolTensor: TypeAlias = torch.BoolTensor\n",
    "Module: TypeAlias = torch.nn.Module\n",
    "IterableDataset: TypeAlias = torch.utils.data.IterableDataset\n",
    "\n",
    "PI = math.pi\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa72fd1-c26d-4edb-b25a-49ee4ca26ec5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5aa870-266d-4def-8fff-46519856f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingBlock(torch.nn.Module):\n",
    "    \"\"\"Pair of coupling layers.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transform,\n",
    "        lattice_shape: list[int],\n",
    "        net_hidden_shape: list[int],\n",
    "        net_activation: Module,\n",
    "        net_final_activation: Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.register_buffer(\"mask\", utils.make_checkerboard(lattice_shape))\n",
    "\n",
    "        half_lattice = utils.prod(lattice_shape) // 2\n",
    "        nodes = [\n",
    "            half_lattice,\n",
    "            *net_hidden_shape,\n",
    "            half_lattice * self.transform.params_dof,\n",
    "        ]\n",
    "        activations = [net_activation for _ in net_hidden_shape] + [\n",
    "            net_final_activation\n",
    "        ]\n",
    "        net_a, net_b = [], []\n",
    "        for d_in, d_out, f_act in zip(nodes[:-1], nodes[1:], activations):\n",
    "            net_a.append(torch.nn.Linear(d_in, d_out))\n",
    "            net_b.append(torch.nn.Linear(d_in, d_out))\n",
    "            net_a.append(f_act)\n",
    "            net_b.append(f_act)\n",
    "        self.net_a = torch.nn.Sequential(*net_a)\n",
    "        self.net_b = torch.nn.Sequential(*net_b)\n",
    "\n",
    "    def forward(self, inputs: Tensor, log_det_jacob: Tensor) -> tuple[Tensor]:\n",
    "        in_a = inputs[:, self.mask]\n",
    "        in_b = inputs[:, ~self.mask]\n",
    "        out_a, log_det_jacob_a = self.transform(\n",
    "            in_a, self.net_b(in_b).view(*in_a.shape, -1).squeeze(dim=-1)\n",
    "        )\n",
    "        out_b, log_det_jacob_b = self.transform(\n",
    "            in_b, self.net_a(out_a).view(*in_b.shape, -1).squeeze(dim=-1)\n",
    "        )\n",
    "        log_det_jacob.add_(log_det_jacob_a + log_det_jacob_b)\n",
    "        outputs = torch.empty_like(inputs)\n",
    "        outputs[:, self.mask] = out_a\n",
    "        outputs[:, ~self.mask] = out_b\n",
    "        return outputs, log_det_jacob\n",
    "\n",
    "    def inverse(self, inputs: Tensor, log_det_jacob: Tensor) -> tuple[Tensor]:\n",
    "        in_a = inputs[:, self.mask]\n",
    "        in_b = inputs[:, ~self.mask]\n",
    "        out_b, log_det_jacob_b = self.transform.inverse(\n",
    "            in_b, self.net_a(in_a).view(*in_b.shape, -1).squeeze(dim=-1)\n",
    "        )\n",
    "        out_a, log_det_jacob_a = self.transform.inverse(\n",
    "            in_a, self.net_b(out_b).view(*in_a.shape, -1).squeeze(dim=-1)\n",
    "        )\n",
    "        log_det_jacob.add_(log_det_jacob_a + log_det_jacob_b)\n",
    "        outputs = torch.empty_like(inputs)\n",
    "        outputs[:, self.mask] = out_a\n",
    "        outputs[:, ~self.mask] = out_b\n",
    "        return outputs, log_det_jacob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989166e4-7631-40b7-a322-6f96b7b51971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    \"\"\"Module which learns to sample from XY model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        xy_coupling: float,\n",
    "        lattice_shape: list[int],\n",
    "        n_blocks: int,\n",
    "        n_spline_segments: int,\n",
    "        net_hidden_shape: list[int],\n",
    "        net_activation: torch.nn.Module,\n",
    "        use_shift_coupling_layers: bool = False,\n",
    "        use_random_rotations: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(n_blocks):\n",
    "            if use_shift_coupling_layers:\n",
    "                layers.append(\n",
    "                    CouplingBlock(\n",
    "                        transforms.PointwisePhaseShift(),\n",
    "                        lattice_shape,\n",
    "                        net_hidden_shape,\n",
    "                        net_activation=torch.nn.Tanh(),\n",
    "                        net_final_activation=torch.nn.Hardtanh(-PI, PI),\n",
    "                    )\n",
    "                )\n",
    "            if use_random_rotations:\n",
    "                layers.append(utils.RandomRotationLayer())\n",
    "            layers.append(\n",
    "                CouplingBlock(\n",
    "                    transforms.PointwiseRationalQuadraticSplineTransform(\n",
    "                        n_spline_segments\n",
    "                    ),\n",
    "                    lattice_shape,\n",
    "                    net_hidden_shape,\n",
    "                    net_activation,\n",
    "                    net_final_activation=torch.nn.Identity(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.flow = utils.Flow(*layers)\n",
    "        self.action = actions.XYSpinAction(xy_coupling)\n",
    "        self.curr_iter = 0\n",
    "\n",
    "    def _save_checkpoint(self):\n",
    "        \"\"\"Hack: should be done automatically by Lightning but I never progress\n",
    "        past epoch=0 and this is easier than fiddling with other things.\n",
    "        \"\"\"\n",
    "        self.trainer.save_checkpoint(\n",
    "            self.logger.log_dir + f\"/checkpoints/iter_{self.curr_iter}.ckpt\"\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"z ~ Unif -> x ~ XY\"\"\"\n",
    "        z, log_prob_z = batch\n",
    "        x, log_det_jacob = self.flow(z)\n",
    "        weights = log_prob_z - log_det_jacob + self.action(x)\n",
    "        return x, weights\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self._save_checkpoint()\n",
    "        # Dirty but more convenient than saving / loading config files atm\n",
    "        self.logger.log_hyperparams(self.hparams)\n",
    "\n",
    "    def on_train_end(self):\n",
    "        self._save_checkpoint()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, weights = self.forward(batch)\n",
    "        loss = weights.mean()\n",
    "        self.log(\"loss\", loss, logger=True)\n",
    "        self.lr_schedulers().step()  # must be called manually since lightning 1.3!!\n",
    "        self.curr_iter += 1\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, weights = self.forward(batch)\n",
    "        loss = weights.mean()\n",
    "        metrics = dict(\n",
    "            loss=loss,\n",
    "            acceptance=utils.metropolis_acceptance(weights),\n",
    "            mag_sq=utils.magnetisation_sq(x).mean(),\n",
    "        )\n",
    "        self.log_dict(\n",
    "            metrics,\n",
    "            prog_bar=False,\n",
    "            logger=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.flow.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.trainer.max_steps\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, prior: IterableDataset, n_iter: int = 1):\n",
    "        x, weights = self.forward(next(prior))\n",
    "        for _ in range(n_iter - 1):\n",
    "            _x, _weights = self.forward(next(prior))\n",
    "            x = torch.cat((x, _x), dim=0)\n",
    "            weights = torch.cat((weights, _weights), dim=0)\n",
    "        return x, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb3d87-0a7f-4b42-b1fa-6bf894fe1ca8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9275b66-5042-447c-954a-418cbad15446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XY parameters\n",
    "LATTICE_SHAPE = [6]\n",
    "XY_COUPLING = 1\n",
    "\n",
    "# Model parameters\n",
    "N_BLOCKS = 2\n",
    "N_SPLINE_SEGMENTS = 8\n",
    "NET_HIDDEN_SHAPE = [32]\n",
    "NET_ACTIVATION = torch.nn.Tanh()\n",
    "USE_SHIFT_COUPLING_LAYERS = True\n",
    "USE_RANDOM_ROTATIONS = True\n",
    "\n",
    "# Training hyperparameters\n",
    "N_TRAIN = 10000\n",
    "N_BATCH = 1000\n",
    "N_BATCH_VAL = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ab715-9082-44f0-bfe2-ea8d2984e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    xy_coupling=XY_COUPLING,\n",
    "    lattice_shape=LATTICE_SHAPE,\n",
    "    n_blocks=N_BLOCKS,\n",
    "    n_spline_segments=N_SPLINE_SEGMENTS,\n",
    "    net_hidden_shape=NET_HIDDEN_SHAPE,\n",
    "    net_activation=NET_ACTIVATION,\n",
    "    use_shift_coupling_layers=USE_SHIFT_COUPLING_LAYERS,\n",
    "    use_random_rotations=USE_RANDOM_ROTATIONS,\n",
    ")\n",
    "\n",
    "# Could wrap in DataSet(IterableDataset, batch_size=None) but can't currently see benefit\n",
    "unif = torch.distributions.Uniform(-PI, PI)\n",
    "train_dataloader = utils.Prior(\n",
    "    distribution=unif, sample_shape=[N_BATCH, *LATTICE_SHAPE]\n",
    ")\n",
    "val_dataloader = utils.Prior(\n",
    "    distribution=unif, sample_shape=[N_BATCH_VAL, *LATTICE_SHAPE]\n",
    ")\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    save_dir=\"test\",\n",
    "    name=\"spins\",\n",
    ")\n",
    "pbar = utils.JlabProgBar()\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_steps=N_TRAIN,  # total number of training steps\n",
    "    val_check_interval=100,  # how often to run sampling\n",
    "    limit_val_batches=1,  # one batch for each val step\n",
    "    # logger=logger,\n",
    "    callbacks=[pbar, lr_monitor],\n",
    "    enable_checkpointing=False,  # manually saving checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dedf1d-c044-4e7e-b5aa-34c8870f6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a5510-69f0-4a92-bb51-6254ca55ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that loading checkpoint works\n",
    "_reloaded_model = Model.load_from_checkpoint(\n",
    "    trainer.log_dir + f\"/checkpoints/iter_{N_TRAIN}.ckpt\",\n",
    "    # action=XYAction(J=1.1),  # could change some of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b9fc4-11ea-4e31-b9e6-896f24e8e5f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45484783-487d-4f61-a45b-3039af2d272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, weights = model.sample(val_dataloader, n_iter=10)\n",
    "model.logger.experiment.add_histogram(\"spins\", x.flatten(), trainer.current_epoch)\n",
    "model.logger.experiment.add_histogram(\n",
    "    \"links\", utils.spins_to_links(x).flatten(), trainer.current_epoch\n",
    ")\n",
    "model.logger.experiment.add_histogram(\"weights\", weights, trainer.current_epoch)\n",
    "model.logger.experiment.add_histogram(\n",
    "    \"magnetisation_sq\", utils.magnetisation_sq(x), trainer.current_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d0bee-a322-42b1-a8a5-4e55c71a740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d83b61-dc83-4067-b2fb-42bc13fa287e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Checking the O(2) symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020f80c-0899-4429-87f1-ed7776eabbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_BATCH = 1000\n",
    "N_ROTATIONS = 100\n",
    "\n",
    "angles = torch.linspace(0, 2 * PI, N_ROTATIONS)\n",
    "x, _ = model.sample(utils.Prior(unif, [N_BATCH, *LATTICE_SHAPE]))\n",
    "action = model.action(x)\n",
    "log_prob_model = torch.empty((N_BATCH, N_ROTATIONS))\n",
    "\n",
    "for i, angle in enumerate(angles):\n",
    "    x_rotated = x.add(PI).add(angle).fmod(2 * PI).sub(PI)\n",
    "    assert torch.allclose(action, model.action(x_rotated), atol=1e-5)\n",
    "    _, log_det_jacob_inv = model.flow.inverse(x_rotated)\n",
    "    log_prob_model[:, i] = log_det_jacob_inv\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "ax1.set_xlabel(\"log ptilde (of unrotated config)\")\n",
    "ax1.set_ylabel(\"std dev of log ptilde\")\n",
    "ax1.scatter(log_prob_model[:, 0].tolist(), log_prob_model.std(dim=1).tolist())\n",
    "\n",
    "ax2.set_xlabel(\"std dev of log ptilde\")\n",
    "ax2.set_ylabel(\"frequency\")\n",
    "ax2.hist(log_prob_model.std(dim=1).tolist())\n",
    "\n",
    "ax3.set_xlabel(\"rotation angle\")\n",
    "ax3.set_ylabel(\"log ptilde\")\n",
    "for i in range(6):\n",
    "    ax3.plot(angles.tolist(), log_prob_model[i].tolist())\n",
    "\n",
    "ax4.set_xlabel(\"rotation_angle\")\n",
    "ax4.set_ylabel(\"<log ptilde>\")\n",
    "ax4.plot(angles.tolist(), log_prob_model.mean(dim=0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb9846-7d97-4346-b5c5-1f570759f1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
